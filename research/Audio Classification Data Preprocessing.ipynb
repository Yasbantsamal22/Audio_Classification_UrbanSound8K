{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526d2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692daf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yasba\\\\OneDrive\\\\Documents\\\\Projects\\\\Audio_Classification_UrbanSound8K\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc02d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7a9dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yasba\\\\OneDrive\\\\Documents\\\\Projects\\\\Audio_Classification_UrbanSound8K'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3f7aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's read a sample audio using librosa\n",
    "import librosa\n",
    "audio_file_path = r'C:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\data\\raw\\fold1\\9031-3-3-0.wav'\n",
    "librosa_audio_data, librosa_sample_rate = librosa.load(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27825d5a-d19e-42c9-bd85-b5036c585297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05424668 0.0778658  0.06725552 ... 0.07426675 0.07336666 0.08047701]\n"
     ]
    }
   ],
   "source": [
    "print(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1784cf17-bb4a-41e0-930d-dff2edf10a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cd0ccb3790>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's plot the librosa audio data\n",
    "import matplotlib.pyplot as plt\n",
    "# Original audio with 1 channel\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101aac2-c67d-480b-a93c-1b47553b677e",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Here Librosa converts the signal to mono, meaning the channel will always be 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a4b0e-a245-40c2-9b27-aac10ff927a0",
   "metadata": {},
   "source": [
    "**Extract Features**\n",
    "\n",
    "Here we will be using Mel-Frequency Cepstral Coefficient(MFCC) from the audio samples. The MFCC Summarises the frequency distribution across the window size, so it is possible to analyse both the frequency and time characteristics of the sound. these audio representations will allow us to identify features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "251e3995-f181-4c3f-8b87-e81f7b00f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 75)\n"
     ]
    }
   ],
   "source": [
    "mfcc = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d8ce8cb-7f1d-4170-8c89-aaa9e22c68da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.05890625e+02, -3.35162384e+02, -2.75130829e+02, ...,\n",
       "        -3.73950043e+02, -3.44669159e+02, -2.87315552e+02],\n",
       "       [ 1.14268600e+02,  1.04809540e+02, -5.22994270e+01, ...,\n",
       "        -3.38385391e+00,  6.14054337e+01,  9.21986847e+01],\n",
       "       [ 1.50286827e+01, -1.11787872e+01, -1.06178185e+02, ...,\n",
       "        -7.99420471e+01, -1.18086891e+01,  2.19801674e+01],\n",
       "       ...,\n",
       "       [ 1.58183181e+00, -5.97155666e+00,  7.09352255e-01, ...,\n",
       "         5.85048318e-01,  1.41096389e+00,  1.62975812e+00],\n",
       "       [ 1.04925191e+00,  1.00868015e+01,  8.79019165e+00, ...,\n",
       "         1.23267865e+00,  3.66824865e+00,  3.24818945e+00],\n",
       "       [ 2.49328613e+00,  4.05441093e+00,  6.66254616e+00, ...,\n",
       "         1.08980665e+01,  4.55692720e+00, -5.90178967e-02]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57d2243a-5a69-45c3-a611-ec6a8798bff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extracting MFCC'S for every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path = 'data\\\\raw'\n",
    "csv_path = r\"C:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\data\\UrbanSound8K.csv\"\n",
    "metadata = pd.read_csv(csv_path)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09980971-9ca3-4ab5-b016-3db6dbbf30d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"class\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4f16751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "782160e6-0e99-493d-ad41-06e9eb130f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name)\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99798aee-51bf-4e9c-80e5-39272d554d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3554it [00:54, 66.23it/s] c:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8320it [02:04, 86.05it/s] c:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "c:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [02:09, 67.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "## Now we iterate through every audio file and extract features\n",
    "## using Mel-Frequency Cepstral Coefficients\n",
    "## C:\\Users\\yasba\\OneDrive\\Documents\\Projects\\Audio_Classification_UrbanSound8K\\data\\raw\\fold1\\7061-6-0-0.wav\n",
    "extracted_features = []\n",
    "for index_num, row in tqdm(metadata.iterrows()):\n",
    "    file_name = str(os.path.join(os.path.abspath(audio_dataset_path), f'fold{row[\"fold\"]}', row[\"slice_file_name\"]))\n",
    "    final_class_labels = row[\"class\"]\n",
    "    data = feature_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cb024c2-469c-4f01-af2a-1103badcb039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-211.93698, 62.581203, -122.81315, -60.745293...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-417.0052, 99.336624, -42.995586, 51.073326, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-452.39316, 112.36253, -37.578068, 43.195866,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-406.47922, 91.1966, -25.043558, 42.78452, 11...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-439.63873, 103.86224, -42.658787, 50.690277,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Features             Class\n",
       "0  [-211.93698, 62.581203, -122.81315, -60.745293...          dog_bark\n",
       "1  [-417.0052, 99.336624, -42.995586, 51.073326, ...  children_playing\n",
       "2  [-452.39316, 112.36253, -37.578068, 43.195866,...  children_playing\n",
       "3  [-406.47922, 91.1966, -25.043558, 42.78452, 11...  children_playing\n",
       "4  [-439.63873, 103.86224, -42.658787, 50.690277,...  children_playing"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=[\"Features\",\"Class\"])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "587df2f7-5744-4e91-b783-9b50cf717c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the dataset into independent and dependent dataset\n",
    "X = np.array(extracted_features_df[\"Features\"].tolist())\n",
    "y = np.array(extracted_features_df[\"Class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5213cc3-aa3c-462b-ba2d-79ce963a083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8732, 40), (8732,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8ffdb63-3d01-4839-bc4d-7dab56bffda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee698446-b2e1-41ac-8eda-31b56e601800",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba0595b4-65f0-4f01-b1a9-9811731952d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6985, 40), (1747, 40), (6985,), (1747,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa499f-7eab-4dd0-bb21-b0100a96c141",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb239885-6278-4e2e-8d71-133a3786b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f01dc5bd-5e98-4215-9896-47321810bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91955130-cd81-4468-ae6c-59bc24136bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = Sequential()\n",
    "\n",
    "## First Layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Second Layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Third Layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Final Layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad7c1d23-2000-4c9a-a173-98ba7ec8840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45410 (177.38 KB)\n",
      "Trainable params: 45410 (177.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "114e7234-19c4-46f6-a062-417bff445a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "## Use categorical_crossentropy if the target variable is label encoded\n",
    "## Else use sparse_categorical_crossentropy if target variable is onehot encode or other format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa2dbac7-872d-4fa0-bc1b-858bde133cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.9311 - accuracy: 0.6860\n",
      "Epoch 1: val_loss improved from inf to 0.70274, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9432 - accuracy: 0.6827 - val_loss: 0.7027 - val_accuracy: 0.7790\n",
      "Epoch 2/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9379 - accuracy: 0.6789\n",
      "Epoch 2: val_loss improved from 0.70274 to 0.69517, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9414 - accuracy: 0.6775 - val_loss: 0.6952 - val_accuracy: 0.7745\n",
      "Epoch 3/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.6795\n",
      "Epoch 3: val_loss did not improve from 0.69517\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9582 - accuracy: 0.6802 - val_loss: 0.7435 - val_accuracy: 0.7802\n",
      "Epoch 4/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9533 - accuracy: 0.6742\n",
      "Epoch 4: val_loss did not improve from 0.69517\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9518 - accuracy: 0.6750 - val_loss: 0.7224 - val_accuracy: 0.7716\n",
      "Epoch 5/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9449 - accuracy: 0.6873\n",
      "Epoch 5: val_loss improved from 0.69517 to 0.69390, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.6882 - val_loss: 0.6939 - val_accuracy: 0.7773\n",
      "Epoch 6/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.6822\n",
      "Epoch 6: val_loss improved from 0.69390 to 0.68913, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9442 - accuracy: 0.6805 - val_loss: 0.6891 - val_accuracy: 0.7750\n",
      "Epoch 7/100\n",
      "192/219 [=========================>....] - ETA: 0s - loss: 0.9261 - accuracy: 0.6862\n",
      "Epoch 7: val_loss did not improve from 0.68913\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9282 - accuracy: 0.6869 - val_loss: 0.7065 - val_accuracy: 0.7779\n",
      "Epoch 8/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9329 - accuracy: 0.6858\n",
      "Epoch 8: val_loss did not improve from 0.68913\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9352 - accuracy: 0.6846 - val_loss: 0.7032 - val_accuracy: 0.7670\n",
      "Epoch 9/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9441 - accuracy: 0.6864\n",
      "Epoch 9: val_loss did not improve from 0.68913\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.6865 - val_loss: 0.6902 - val_accuracy: 0.7796\n",
      "Epoch 10/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9469 - accuracy: 0.6871\n",
      "Epoch 10: val_loss did not improve from 0.68913\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9467 - accuracy: 0.6862 - val_loss: 0.7331 - val_accuracy: 0.7642\n",
      "Epoch 11/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9607 - accuracy: 0.6792\n",
      "Epoch 11: val_loss improved from 0.68913 to 0.68743, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9539 - accuracy: 0.6800 - val_loss: 0.6874 - val_accuracy: 0.7865\n",
      "Epoch 12/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.9307 - accuracy: 0.6881\n",
      "Epoch 12: val_loss did not improve from 0.68743\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9340 - accuracy: 0.6880 - val_loss: 0.7115 - val_accuracy: 0.7676\n",
      "Epoch 13/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9189 - accuracy: 0.6852\n",
      "Epoch 13: val_loss improved from 0.68743 to 0.68197, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9191 - accuracy: 0.6856 - val_loss: 0.6820 - val_accuracy: 0.7831\n",
      "Epoch 14/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.6869\n",
      "Epoch 14: val_loss did not improve from 0.68197\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9293 - accuracy: 0.6865 - val_loss: 0.6941 - val_accuracy: 0.7819\n",
      "Epoch 15/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9413 - accuracy: 0.6824\n",
      "Epoch 15: val_loss did not improve from 0.68197\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9419 - accuracy: 0.6825 - val_loss: 0.6832 - val_accuracy: 0.7922\n",
      "Epoch 16/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9428 - accuracy: 0.6871\n",
      "Epoch 16: val_loss did not improve from 0.68197\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9453 - accuracy: 0.6866 - val_loss: 0.6854 - val_accuracy: 0.7831\n",
      "Epoch 17/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9382 - accuracy: 0.6841\n",
      "Epoch 17: val_loss improved from 0.68197 to 0.67144, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9409 - accuracy: 0.6833 - val_loss: 0.6714 - val_accuracy: 0.7865\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.6932\n",
      "Epoch 18: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9220 - accuracy: 0.6932 - val_loss: 0.6926 - val_accuracy: 0.7859\n",
      "Epoch 19/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 0.9331 - accuracy: 0.6844\n",
      "Epoch 19: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9293 - accuracy: 0.6865 - val_loss: 0.6745 - val_accuracy: 0.8008\n",
      "Epoch 20/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9240 - accuracy: 0.6881\n",
      "Epoch 20: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9241 - accuracy: 0.6883 - val_loss: 0.6828 - val_accuracy: 0.7876\n",
      "Epoch 21/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9357 - accuracy: 0.6833\n",
      "Epoch 21: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9302 - accuracy: 0.6858 - val_loss: 0.6910 - val_accuracy: 0.7865\n",
      "Epoch 22/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9190 - accuracy: 0.6929\n",
      "Epoch 22: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9128 - accuracy: 0.6958 - val_loss: 0.6775 - val_accuracy: 0.7899\n",
      "Epoch 23/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9275 - accuracy: 0.6908\n",
      "Epoch 23: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9268 - accuracy: 0.6911 - val_loss: 0.6964 - val_accuracy: 0.7836\n",
      "Epoch 24/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9431 - accuracy: 0.6847\n",
      "Epoch 24: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9428 - accuracy: 0.6840 - val_loss: 0.6854 - val_accuracy: 0.7911\n",
      "Epoch 25/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.9158 - accuracy: 0.6924\n",
      "Epoch 25: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9115 - accuracy: 0.6943 - val_loss: 0.6965 - val_accuracy: 0.7836\n",
      "Epoch 26/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.9192 - accuracy: 0.6933\n",
      "Epoch 26: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9235 - accuracy: 0.6915 - val_loss: 0.6715 - val_accuracy: 0.7888\n",
      "Epoch 27/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9221 - accuracy: 0.6901\n",
      "Epoch 27: val_loss did not improve from 0.67144\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9239 - accuracy: 0.6899 - val_loss: 0.6900 - val_accuracy: 0.7762\n",
      "Epoch 28/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9095 - accuracy: 0.6902\n",
      "Epoch 28: val_loss improved from 0.67144 to 0.67046, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9123 - accuracy: 0.6905 - val_loss: 0.6705 - val_accuracy: 0.8002\n",
      "Epoch 29/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9068 - accuracy: 0.6953\n",
      "Epoch 29: val_loss did not improve from 0.67046\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9079 - accuracy: 0.6949 - val_loss: 0.6845 - val_accuracy: 0.7848\n",
      "Epoch 30/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.9104 - accuracy: 0.6860\n",
      "Epoch 30: val_loss did not improve from 0.67046\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9119 - accuracy: 0.6863 - val_loss: 0.6868 - val_accuracy: 0.7790\n",
      "Epoch 31/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9075 - accuracy: 0.6925\n",
      "Epoch 31: val_loss improved from 0.67046 to 0.65930, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9100 - accuracy: 0.6919 - val_loss: 0.6593 - val_accuracy: 0.7865\n",
      "Epoch 32/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9131 - accuracy: 0.6933\n",
      "Epoch 32: val_loss did not improve from 0.65930\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9135 - accuracy: 0.6923 - val_loss: 0.6765 - val_accuracy: 0.7916\n",
      "Epoch 33/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8990 - accuracy: 0.7028\n",
      "Epoch 33: val_loss did not improve from 0.65930\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8999 - accuracy: 0.7019 - val_loss: 0.6958 - val_accuracy: 0.7888\n",
      "Epoch 34/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9302 - accuracy: 0.6864\n",
      "Epoch 34: val_loss did not improve from 0.65930\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9249 - accuracy: 0.6883 - val_loss: 0.6642 - val_accuracy: 0.7939\n",
      "Epoch 35/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.9191 - accuracy: 0.6936\n",
      "Epoch 35: val_loss improved from 0.65930 to 0.64929, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9157 - accuracy: 0.6942 - val_loss: 0.6493 - val_accuracy: 0.7956\n",
      "Epoch 36/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9018 - accuracy: 0.6979\n",
      "Epoch 36: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9024 - accuracy: 0.6986 - val_loss: 0.6663 - val_accuracy: 0.7934\n",
      "Epoch 37/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.8919 - accuracy: 0.6960\n",
      "Epoch 37: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8925 - accuracy: 0.6969 - val_loss: 0.6550 - val_accuracy: 0.7951\n",
      "Epoch 38/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.9030 - accuracy: 0.7011\n",
      "Epoch 38: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9063 - accuracy: 0.7009 - val_loss: 0.6604 - val_accuracy: 0.7974\n",
      "Epoch 39/100\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 0.9218 - accuracy: 0.6894\n",
      "Epoch 39: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9247 - accuracy: 0.6899 - val_loss: 0.6927 - val_accuracy: 0.7796\n",
      "Epoch 40/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.9135 - accuracy: 0.6947\n",
      "Epoch 40: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9130 - accuracy: 0.6952 - val_loss: 0.6545 - val_accuracy: 0.7974\n",
      "Epoch 41/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9031 - accuracy: 0.6999\n",
      "Epoch 41: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9012 - accuracy: 0.6995 - val_loss: 0.6648 - val_accuracy: 0.7894\n",
      "Epoch 42/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.8830 - accuracy: 0.7027\n",
      "Epoch 42: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8873 - accuracy: 0.7034 - val_loss: 0.6682 - val_accuracy: 0.7962\n",
      "Epoch 43/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9062 - accuracy: 0.6966\n",
      "Epoch 43: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9054 - accuracy: 0.6971 - val_loss: 0.6734 - val_accuracy: 0.7756\n",
      "Epoch 44/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.9190 - accuracy: 0.6867\n",
      "Epoch 44: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9174 - accuracy: 0.6885 - val_loss: 0.6775 - val_accuracy: 0.7899\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8994 - accuracy: 0.7019\n",
      "Epoch 45: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8994 - accuracy: 0.7019 - val_loss: 0.6674 - val_accuracy: 0.7813\n",
      "Epoch 46/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.9206 - accuracy: 0.6901\n",
      "Epoch 46: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9175 - accuracy: 0.6921 - val_loss: 0.6601 - val_accuracy: 0.7853\n",
      "Epoch 47/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9082 - accuracy: 0.7027\n",
      "Epoch 47: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9056 - accuracy: 0.7031 - val_loss: 0.6563 - val_accuracy: 0.7951\n",
      "Epoch 48/100\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.8722 - accuracy: 0.7090\n",
      "Epoch 48: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8832 - accuracy: 0.7068 - val_loss: 0.6619 - val_accuracy: 0.7819\n",
      "Epoch 49/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9002 - accuracy: 0.6944\n",
      "Epoch 49: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8984 - accuracy: 0.6951 - val_loss: 0.6529 - val_accuracy: 0.7974\n",
      "Epoch 50/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9023 - accuracy: 0.6979\n",
      "Epoch 50: val_loss did not improve from 0.64929\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9005 - accuracy: 0.6988 - val_loss: 0.6548 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8950 - accuracy: 0.7008\n",
      "Epoch 51: val_loss improved from 0.64929 to 0.64779, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8962 - accuracy: 0.7002 - val_loss: 0.6478 - val_accuracy: 0.7962\n",
      "Epoch 52/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.8749 - accuracy: 0.7023\n",
      "Epoch 52: val_loss improved from 0.64779 to 0.63985, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8774 - accuracy: 0.7014 - val_loss: 0.6399 - val_accuracy: 0.8002\n",
      "Epoch 53/100\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 0.9119 - accuracy: 0.6918\n",
      "Epoch 53: val_loss did not improve from 0.63985\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8975 - accuracy: 0.6972 - val_loss: 0.6502 - val_accuracy: 0.8037\n",
      "Epoch 54/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.8862 - accuracy: 0.7027\n",
      "Epoch 54: val_loss did not improve from 0.63985\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8887 - accuracy: 0.7018 - val_loss: 0.6700 - val_accuracy: 0.7853\n",
      "Epoch 55/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9086 - accuracy: 0.6972\n",
      "Epoch 55: val_loss did not improve from 0.63985\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9079 - accuracy: 0.6979 - val_loss: 0.6596 - val_accuracy: 0.8019\n",
      "Epoch 56/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.9139 - accuracy: 0.6903\n",
      "Epoch 56: val_loss did not improve from 0.63985\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9092 - accuracy: 0.6925 - val_loss: 0.6569 - val_accuracy: 0.7945\n",
      "Epoch 57/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9167 - accuracy: 0.6919\n",
      "Epoch 57: val_loss did not improve from 0.63985\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9144 - accuracy: 0.6932 - val_loss: 0.6452 - val_accuracy: 0.7979\n",
      "Epoch 58/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9118 - accuracy: 0.6938\n",
      "Epoch 58: val_loss improved from 0.63985 to 0.63542, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.9097 - accuracy: 0.6938 - val_loss: 0.6354 - val_accuracy: 0.8077\n",
      "Epoch 59/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8734 - accuracy: 0.7089\n",
      "Epoch 59: val_loss improved from 0.63542 to 0.62002, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8685 - accuracy: 0.7101 - val_loss: 0.6200 - val_accuracy: 0.7968\n",
      "Epoch 60/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9021 - accuracy: 0.7018\n",
      "Epoch 60: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8991 - accuracy: 0.7022 - val_loss: 0.6479 - val_accuracy: 0.7974\n",
      "Epoch 61/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8660 - accuracy: 0.7063\n",
      "Epoch 61: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8662 - accuracy: 0.7064 - val_loss: 0.6335 - val_accuracy: 0.7985\n",
      "Epoch 62/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8831 - accuracy: 0.7042\n",
      "Epoch 62: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8822 - accuracy: 0.7041 - val_loss: 0.6621 - val_accuracy: 0.7916\n",
      "Epoch 63/100\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.8812 - accuracy: 0.7013\n",
      "Epoch 63: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8852 - accuracy: 0.7002 - val_loss: 0.6464 - val_accuracy: 0.7985\n",
      "Epoch 64/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8856 - accuracy: 0.6920\n",
      "Epoch 64: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8863 - accuracy: 0.6919 - val_loss: 0.6506 - val_accuracy: 0.7871\n",
      "Epoch 65/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.9151 - accuracy: 0.6964\n",
      "Epoch 65: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9071 - accuracy: 0.6971 - val_loss: 0.6545 - val_accuracy: 0.7951\n",
      "Epoch 66/100\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.8867 - accuracy: 0.7059\n",
      "Epoch 66: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8877 - accuracy: 0.7042 - val_loss: 0.6413 - val_accuracy: 0.7968\n",
      "Epoch 67/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8887 - accuracy: 0.6979\n",
      "Epoch 67: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8886 - accuracy: 0.6975 - val_loss: 0.6411 - val_accuracy: 0.7945\n",
      "Epoch 68/100\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.8898 - accuracy: 0.7037\n",
      "Epoch 68: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8911 - accuracy: 0.7032 - val_loss: 0.6578 - val_accuracy: 0.7842\n",
      "Epoch 69/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9043 - accuracy: 0.7000\n",
      "Epoch 69: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9062 - accuracy: 0.7002 - val_loss: 0.6416 - val_accuracy: 0.7974\n",
      "Epoch 70/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8886 - accuracy: 0.7081\n",
      "Epoch 70: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8921 - accuracy: 0.7071 - val_loss: 0.6599 - val_accuracy: 0.7916\n",
      "Epoch 71/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.8776 - accuracy: 0.7054\n",
      "Epoch 71: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8774 - accuracy: 0.7047 - val_loss: 0.6390 - val_accuracy: 0.8008\n",
      "Epoch 72/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8879 - accuracy: 0.7045\n",
      "Epoch 72: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8851 - accuracy: 0.7052 - val_loss: 0.6288 - val_accuracy: 0.7991\n",
      "Epoch 73/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8721 - accuracy: 0.7081\n",
      "Epoch 73: val_loss did not improve from 0.62002\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8721 - accuracy: 0.7084 - val_loss: 0.6470 - val_accuracy: 0.7945\n",
      "Epoch 74/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8716 - accuracy: 0.7094\n",
      "Epoch 74: val_loss improved from 0.62002 to 0.61481, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8672 - accuracy: 0.7112 - val_loss: 0.6148 - val_accuracy: 0.8071\n",
      "Epoch 75/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8660 - accuracy: 0.7091\n",
      "Epoch 75: val_loss did not improve from 0.61481\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8626 - accuracy: 0.7098 - val_loss: 0.6330 - val_accuracy: 0.8002\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8849 - accuracy: 0.7028\n",
      "Epoch 76: val_loss did not improve from 0.61481\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8849 - accuracy: 0.7028 - val_loss: 0.6359 - val_accuracy: 0.8082\n",
      "Epoch 77/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.8495 - accuracy: 0.7180\n",
      "Epoch 77: val_loss did not improve from 0.61481\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8549 - accuracy: 0.7160 - val_loss: 0.6524 - val_accuracy: 0.7894\n",
      "Epoch 78/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.8554 - accuracy: 0.7055\n",
      "Epoch 78: val_loss improved from 0.61481 to 0.61420, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8640 - accuracy: 0.7032 - val_loss: 0.6142 - val_accuracy: 0.8111\n",
      "Epoch 79/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.8577 - accuracy: 0.7136\n",
      "Epoch 79: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8593 - accuracy: 0.7132 - val_loss: 0.6265 - val_accuracy: 0.8014\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.7101\n",
      "Epoch 80: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8670 - accuracy: 0.7101 - val_loss: 0.6215 - val_accuracy: 0.8151\n",
      "Epoch 81/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8664 - accuracy: 0.7116\n",
      "Epoch 81: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8685 - accuracy: 0.7111 - val_loss: 0.6261 - val_accuracy: 0.8060\n",
      "Epoch 82/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8896 - accuracy: 0.7054\n",
      "Epoch 82: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8903 - accuracy: 0.7054 - val_loss: 0.6225 - val_accuracy: 0.8060\n",
      "Epoch 83/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8674 - accuracy: 0.7102\n",
      "Epoch 83: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8734 - accuracy: 0.7075 - val_loss: 0.6193 - val_accuracy: 0.8054\n",
      "Epoch 84/100\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.8947 - accuracy: 0.7022\n",
      "Epoch 84: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8955 - accuracy: 0.7014 - val_loss: 0.6421 - val_accuracy: 0.7962\n",
      "Epoch 85/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8846 - accuracy: 0.7116\n",
      "Epoch 85: val_loss did not improve from 0.61420\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8798 - accuracy: 0.7128 - val_loss: 0.6419 - val_accuracy: 0.8008\n",
      "Epoch 86/100\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.8832 - accuracy: 0.7066\n",
      "Epoch 86: val_loss improved from 0.61420 to 0.61053, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8851 - accuracy: 0.7064 - val_loss: 0.6105 - val_accuracy: 0.8128\n",
      "Epoch 87/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8617 - accuracy: 0.7074\n",
      "Epoch 87: val_loss did not improve from 0.61053\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8670 - accuracy: 0.7059 - val_loss: 0.6294 - val_accuracy: 0.7945\n",
      "Epoch 88/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8592 - accuracy: 0.7109\n",
      "Epoch 88: val_loss improved from 0.61053 to 0.59615, saving model to saved_models\\audio_classification.h5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8559 - accuracy: 0.7112 - val_loss: 0.5962 - val_accuracy: 0.8117\n",
      "Epoch 89/100\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.8912 - accuracy: 0.7071\n",
      "Epoch 89: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8897 - accuracy: 0.7075 - val_loss: 0.6165 - val_accuracy: 0.8071\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8527 - accuracy: 0.7128\n",
      "Epoch 90: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8527 - accuracy: 0.7128 - val_loss: 0.6091 - val_accuracy: 0.8008\n",
      "Epoch 91/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8603 - accuracy: 0.7114\n",
      "Epoch 91: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8580 - accuracy: 0.7124 - val_loss: 0.6081 - val_accuracy: 0.8065\n",
      "Epoch 92/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8511 - accuracy: 0.7190\n",
      "Epoch 92: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8532 - accuracy: 0.7191 - val_loss: 0.6299 - val_accuracy: 0.7945\n",
      "Epoch 93/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8559 - accuracy: 0.7166\n",
      "Epoch 93: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8572 - accuracy: 0.7162 - val_loss: 0.6213 - val_accuracy: 0.7997\n",
      "Epoch 94/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8568 - accuracy: 0.7154\n",
      "Epoch 94: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8569 - accuracy: 0.7152 - val_loss: 0.6213 - val_accuracy: 0.8014\n",
      "Epoch 95/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8575 - accuracy: 0.7067\n",
      "Epoch 95: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8557 - accuracy: 0.7077 - val_loss: 0.6371 - val_accuracy: 0.8031\n",
      "Epoch 96/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8763 - accuracy: 0.7115\n",
      "Epoch 96: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8747 - accuracy: 0.7115 - val_loss: 0.6368 - val_accuracy: 0.8031\n",
      "Epoch 97/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8482 - accuracy: 0.7198\n",
      "Epoch 97: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8482 - accuracy: 0.7197 - val_loss: 0.6029 - val_accuracy: 0.8122\n",
      "Epoch 98/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8502 - accuracy: 0.7139\n",
      "Epoch 98: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8503 - accuracy: 0.7137 - val_loss: 0.6215 - val_accuracy: 0.7979\n",
      "Epoch 99/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8710 - accuracy: 0.7106\n",
      "Epoch 99: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8695 - accuracy: 0.7110 - val_loss: 0.6171 - val_accuracy: 0.8082\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8851 - accuracy: 0.7105\n",
      "Epoch 100: val_loss did not improve from 0.59615\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.8851 - accuracy: 0.7105 - val_loss: 0.6335 - val_accuracy: 0.8065\n",
      "Training completed in time:  0:01:02.315475\n"
     ]
    }
   ],
   "source": [
    "## Training my model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "# num_classes = 10\n",
    "\n",
    "# # One-hot encode the targets\n",
    "# y_train = to_categorical(y_train, num_classes)\n",
    "# y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test,y_test), callbacks=[checkpointer])\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8790929e-1270-4910-b64f-ec3c8fd06251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806525468826294\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b9a60-17c9-4770-85af-7a2fdae7e10c",
   "metadata": {},
   "source": [
    "## Testing Some Test Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf57d55-b65c-4044-84f1-9bab8b6ff723",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "- Preprocess the new audio data\n",
    "- predict the classes\n",
    "- invere transform the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e60cf65b-2171-466a-8a24-ca18c06cb323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-74.15034     71.171295    -7.2813187  -13.05415      4.0155325\n",
      "  -5.845897    -6.818139    -4.2881436   -8.95169      1.2468196\n",
      "  -7.87719      0.43814105  -7.215785     0.08722974  -7.969287\n",
      "  -4.153098    -9.48869     -2.0341449   -1.6445242    1.6244239\n",
      "  -2.7746882   -4.331586    -9.972777    -8.417545    -7.9463887\n",
      "   0.64830995   2.177376     1.9039183   -6.6562457   -3.7984414\n",
      "  -3.7553144   -0.51080257  -2.8393679   -1.3745583   -7.393749\n",
      "  -1.8019917    0.159959     0.8673938   -5.444731    -2.399574  ]\n",
      "[[-74.15034     71.171295    -7.2813187  -13.05415      4.0155325\n",
      "   -5.845897    -6.818139    -4.2881436   -8.95169      1.2468196\n",
      "   -7.87719      0.43814105  -7.215785     0.08722974  -7.969287\n",
      "   -4.153098    -9.48869     -2.0341449   -1.6445242    1.6244239\n",
      "   -2.7746882   -4.331586    -9.972777    -8.417545    -7.9463887\n",
      "    0.64830995   2.177376     1.9039183   -6.6562457   -3.7984414\n",
      "   -3.7553144   -0.51080257  -2.8393679   -1.3745583   -7.393749\n",
      "   -1.8019917    0.159959     0.8673938   -5.444731    -2.399574  ]]\n",
      "(1, 40)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0.13379815 0.01431695 0.09051828 0.22151177 0.05410344 0.0363427\n",
      "  0.05307069 0.01366964 0.03641167 0.34625673]]\n",
      "[9]\n",
      "This sound is of: ['street_music']\n"
     ]
    }
   ],
   "source": [
    "filename = \"data\\\\raw\\\\fold2\\\\14780-9-0-2.wav\"\n",
    "audio, sample_rate = librosa.load(filename)\n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_sacled_features = np.mean(mfccs_features.T, axis = 0)\n",
    "\n",
    "print(mfccs_sacled_features)\n",
    "mfccs_sacled_features = mfccs_sacled_features.reshape(1,-1)\n",
    "print(mfccs_sacled_features)\n",
    "print(mfccs_sacled_features.shape)\n",
    "predicted_label = model.predict(mfccs_sacled_features)\n",
    "print(predicted_label)\n",
    "# Convert probabilities to class indices\n",
    "predicted_indices = np.argmax(predicted_label, axis=1)\n",
    "prediction_class = le.inverse_transform(predicted_indices)\n",
    "# classes[prediction_class]\n",
    "print(predicted_indices)\n",
    "print(\"This sound is of:\",prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fdfe26a9-375b-429b-8e74-8c4296cbd3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'car_horn', 'air_conditioner',\n",
       "       'street_music', 'gun_shot', 'siren', 'engine_idling', 'jackhammer',\n",
       "       'drilling'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912b85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
